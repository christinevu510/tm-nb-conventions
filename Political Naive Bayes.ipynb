{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes on Political Text\n",
    "\n",
    "In this notebook we use Naive Bayes to explore and classify political data. See the `README.md` for full details. You can download the required DB from the shared dropbox or from blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import nltk\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_db = sqlite3.connect(r'/Users/Chris/Downloads/2020_Conventions.db')\n",
    "convention_cur = convention_db.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Exploratory Naive Bayes\n",
    "\n",
    "We'll first build a NB model on the convention data itself, as a way to understand what words distinguish between the two parties. This is analogous to what we did in the \"Comparing Groups\" class work. First, pull in the text \n",
    "for each party and prepare it for use in Naive Bayes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of stopwords\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Create a set of punctuation marks\n",
    "punctuation = set(string.punctuation)  # Speeds up comparison\n",
    "tw_punct = punctuation - {\"#\"}\n",
    "\n",
    "# Remove stopwords\n",
    "def remove_stop(tokens):\n",
    "    return [w for w in tokens if w.lower() not in sw]\n",
    "\n",
    "# Remove punctuation\n",
    "def remove_punctuation(text, punct_set=tw_punct):\n",
    "    return \"\".join([ch for ch in text if ch not in punct_set])\n",
    "\n",
    "# Tokenize\n",
    "def tokenize(text):\n",
    "    return text.split()\n",
    "\n",
    "# Convert to lowercase\n",
    "def lowercase(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Joins tokens (concatenation)\n",
    "def join_tokens(tokens):\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "# Applies pipeline to text\n",
    "def prepare(text, pipeline):\n",
    "    tokens = str(text)\n",
    "    for transform in pipeline:\n",
    "        tokens = transform(tokens)\n",
    "    return tokens\n",
    "\n",
    "cleaning_pipeline = [lowercase, remove_punctuation, tokenize, remove_stop, join_tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conventions']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve table names\n",
    "convention_cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table';\")\n",
    "\n",
    "# Fetch table names\n",
    "convention_table_names = [row[0] for row in convention_cur.fetchall()]\n",
    "convention_table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "convention_data = []\n",
    "\n",
    "# fill this list up with items that are themselves lists.\n",
    "# The first element in the sublist should be the cleaned and tokenized text in a single string. The second element should be the party. \n",
    "\n",
    "query_results = convention_cur.execute(\"SELECT party, text FROM conventions\")\n",
    "\n",
    "for row in query_results :\n",
    "    party, text = row\n",
    "    lowercased_party = lowercase(party)\n",
    "    lowercased_text = lowercase(text)\n",
    "    clean_text = prepare(lowercased_text, pipeline = cleaning_pipeline)\n",
    "    convention_data.append([clean_text, lowercased_party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some random entries and see if they look right. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['different kind convention', 'democratic'],\n",
       " ['son scranton claymont wilmington become one consequential vice presidents american history accolade nonetheless rest firmly behind legacy husband father grandfather grateful nation thanks vice president joseph r biden jr lifetime service behalf united states america',\n",
       "  'democratic'],\n",
       " ['joe believes stand allies stand adversaries right president turns tragedies political weapons joe president turns challenges purpose joe bring us together build economy doesn’t leave anyone behind good paying job floor ceiling',\n",
       "  'democratic'],\n",
       " ['feeding people act love think use little extra love days took food trucks community deliver meals made right clinton presidential center neighbors need even leaders let us americans kept looking arkansas casts 9 votes bernie sanders 27 votes next president joe biden',\n",
       "  'democratic'],\n",
       " ['well i’m nurses i’m doctors i’m everybody make china virus go away it’s happening please go ahead',\n",
       "  'republican'],\n",
       " ['good evening everyone name nick sandmann i’m teenager defamed media encounter group protesters steps lincoln memorial last year begin i’d like thank president trump opportunity share story matters much november’s election 2019 attended march life washington dc demonstrated defense unborn later day bought make america great hat president donald trump distinguished one prolife presidents history country wanted express support looking back could possibly imagined simple act putting red hat would unleash hate left make target network cable news networks nationwide kentucky birthplace abraham lincoln classmates visited lincoln memorial',\n",
       "  'republican'],\n",
       " ['six incredible people held hostage various countries i’m pleased let everybody know brought back 50 hostages 22 different countries work hard ambassador o’brien others tell we’re proud job i’d like ask maybe pastor brunson say words go give us little history happened life treating',\n",
       "  'republican'],\n",
       " ['joe biden decent man long history public service america', 'democratic'],\n",
       " ['first time met joe really new synagogue funeral service foreign language 000427 towards end service door opens person much younger octogenarians walked room us senator joe biden respectful stayed back head bowed reverence end said “senator biden here” nice irish catholic boy know foreign language 014352 said lovely said “this dear lady gave 18 campaign first time started 1972” wanted show respect saying thank blew away',\n",
       "  'democratic'],\n",
       " ['cities strong people make strong economy come back small businesses bring back louisiana cast 60 votes friend next president joe biden',\n",
       "  'democratic']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices(convention_data, k = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that looks good, we now need to make our function to turn these into features. In my solution, I wanted to keep the number of features reasonable, so I only used words that occur at least `word_cutoff` times. Here's the code to test that if you want it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With a word cutoff of 5, we have 2391 as features in the model.\n"
     ]
    }
   ],
   "source": [
    "word_cutoff = 5\n",
    "\n",
    "tokens = [w for t, p in convention_data for w in t.split()]\n",
    "\n",
    "word_dist = nltk.FreqDist(tokens)\n",
    "\n",
    "feature_words = set()\n",
    "\n",
    "for word, count in word_dist.items() :\n",
    "    if count > word_cutoff :\n",
    "        feature_words.add(word)\n",
    "        \n",
    "print(f\"With a word cutoff of {word_cutoff}, we have {len(feature_words)} as features in the model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_features(text,fw) :\n",
    "        \n",
    "    \"\"\"Given some text, this returns a dictionary holding the\n",
    "       feature words.\n",
    "       \n",
    "       Args: \n",
    "            * text: a piece of text in a continuous string. Assumes\n",
    "            text has been cleaned and case folded.\n",
    "            * fw: the *feature words* that we're considering. A word \n",
    "            in `text` must be in fw in order to be returned. This \n",
    "            prevents us from considering very rarely occurring words.\n",
    "        \n",
    "       Returns: \n",
    "            A dictionary with the words in `text` that appear in `fw`. \n",
    "            Words are only counted once. \n",
    "            If `text` were \"quick quick brown fox\" and `fw` = {'quick','fox','jumps'},\n",
    "            then this would return a dictionary of \n",
    "            {'quick' : True,\n",
    "             'fox' :    True}\n",
    "    \"\"\"\n",
    "        \n",
    "    ret_dict = {word: True for word in text.split() if word in fw}\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(feature_words)>0)\n",
    "assert(conv_features(\"donald is the president\",feature_words)==\n",
    "       {'donald':True,'president':True})\n",
    "assert(conv_features(\"people are american in america\",feature_words)==\n",
    "                     {'america':True,'american':True,\"people\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll build our feature set. Out of curiosity I did a train/test split to see how accurate the classifier was, but we don't strictly need to since this analysis is exploratory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(conv_features(text,feature_words), party) for (text, party) in convention_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220507)\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "test_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "test_set, train_set = featuresets[:test_size], featuresets[test_size:]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(nltk.classify.accuracy(classifier, test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           republ : democr =     25.8 : 1.0\n",
      "                   votes = True           democr : republ =     23.8 : 1.0\n",
      "             enforcement = True           republ : democr =     21.5 : 1.0\n",
      "                 destroy = True           republ : democr =     19.2 : 1.0\n",
      "                freedoms = True           republ : democr =     18.2 : 1.0\n",
      "                 climate = True           democr : republ =     17.8 : 1.0\n",
      "                supports = True           republ : democr =     17.1 : 1.0\n",
      "                   crime = True           republ : democr =     16.1 : 1.0\n",
      "                   media = True           republ : democr =     14.9 : 1.0\n",
      "                 beliefs = True           republ : democr =     13.0 : 1.0\n",
      "               countries = True           republ : democr =     13.0 : 1.0\n",
      "                 defense = True           republ : democr =     13.0 : 1.0\n",
      "                    isis = True           republ : democr =     13.0 : 1.0\n",
      "                 liberal = True           republ : democr =     13.0 : 1.0\n",
      "                religion = True           republ : democr =     13.0 : 1.0\n",
      "                   trade = True           republ : democr =     12.7 : 1.0\n",
      "                    flag = True           republ : democr =     12.1 : 1.0\n",
      "               greatness = True           republ : democr =     12.1 : 1.0\n",
      "                 abraham = True           republ : democr =     11.9 : 1.0\n",
      "                  defund = True           republ : democr =     11.9 : 1.0\n",
      "                    drug = True           republ : democr =     10.9 : 1.0\n",
      "              department = True           republ : democr =     10.9 : 1.0\n",
      "               destroyed = True           republ : democr =     10.9 : 1.0\n",
      "                   enemy = True           republ : democr =     10.9 : 1.0\n",
      "               amendment = True           republ : democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Observations\n",
    "\n",
    "There are differences between Democrats and Republicans. There is an imbalance between the number of words indicating a Republican speaker compared to those suggesting a Demoncratic speaker. Republican speeches exhibit words such as `China`, `enforcement`, `defund`, and `amendment`, which all relate to traditional conservative philosophies. On the other hand, are only two words, `votes` and `climate`, that are associated with Democratic speeches. These words may relate to topics like voting rights and climate change.\n",
    "\n",
    "These patterns in word usage provide insights into the learned patterns of the Naive Bayes classifier. It suggests that the classifier has a higher propensity to associate words with Republican speeches than with Democratic speeches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Classifying Congressional Tweets\n",
    "\n",
    "In this part we apply the classifer we just built to a set of tweets by people running for congress\n",
    "in 2018. These tweets are stored in the database `congressional_data.db`. That DB is funky, so I'll\n",
    "give you the query I used to pull out the tweets. Note that this DB has some big tables and \n",
    "is unindexed, so the query takes a minute or two to run on my machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cong_db = sqlite3.connect(\"/Users/Chris/Downloads/congressional_data.db\")\n",
    "\n",
    "cong_cur = cong_db.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['websites', 'candidate_data', 'tweets']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve table names\n",
    "cong_cur.execute(\"SELECT name FROM sqlite_master WHERE type = 'table';\")\n",
    "\n",
    "# Fetch table names\n",
    "cong_table_names = [row[0] for row in cong_cur.fetchall()]\n",
    "cong_table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = cong_cur.execute(\n",
    "        '''\n",
    "           SELECT DISTINCT \n",
    "                  cd.candidate, \n",
    "                  cd.party,\n",
    "                  tw.tweet_text\n",
    "           FROM candidate_data cd \n",
    "           INNER JOIN tweets tw ON cd.twitter_handle = tw.handle \n",
    "               AND cd.candidate == tw.candidate \n",
    "               AND cd.district == tw.district\n",
    "           WHERE cd.party in ('Republican','Democratic') \n",
    "               AND tw.tweet_text NOT LIKE '%RT%'\n",
    "        ''')\n",
    "\n",
    "results = list(results) # Just to store it, since the query is time consuming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "\n",
    "# Now fill up tweet_data with sublists like we did on the convention speeches.\n",
    "# Note that this may take a bit of time, since we have a lot of tweets.\n",
    "\n",
    "sw = stopwords.words(\"english\")\n",
    "\n",
    "# Iterate through the query results\n",
    "for row in results:\n",
    "    # Unpack the values from the row\n",
    "    candidate, party, tweet_text = row\n",
    "    \n",
    "    # Clean the tweet text using the pipeline\n",
    "    clean_tweet_text = prepare(tweet_text, pipeline = cleaning_pipeline)\n",
    "    \n",
    "    # Append the cleaned tweet text and party to tweet_data\n",
    "    tweet_data.append([clean_tweet_text, party])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of tweets here. Let's take a random sample and see how our classifer does. I'm guessing it won't be too great given the performance on the convention speeches..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20201014)\n",
    "\n",
    "tweet_data_sample = random.choices(tweet_data, k = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's our (cleaned) tweet: bearlier today spoke house floor abt protecting health care women praised ppmarmonte work central coast httpstcowqgtrzt7vv\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bgo tribe #rallytogether httpstco0nxutfl9l5\n",
      "Actual party is Democratic and our classifer says democratic.\n",
      "\n",
      "Here's our (cleaned) tweet: bapparently trump thinks easy students overwhelmed crushing burden debt pay student loans #trumpbudget httpstcockyqo5t0qh\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwexe2x80x99re grateful first responders rescue personnel firefighters police volunteers working tirelessly keep people safe provide muchneeded help putting lives linennhttpstcoezpv0vmiz3\n",
      "Actual party is Republican and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bletxe2x80x99s make even greater #kag xf0x9fx87xbaxf0x9fx87xb8 httpstcoy9qozd5l2z\n",
      "Actual party is Republican and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwe 1hr cavs tie series 22 im #allin216 repbarbaralee scared #roadtovictory\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bcongrats belliottsd new gig sd city hall glad continue servexe2x80xa6 httpstcofkvmw3cqdi\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bwe really close 3500 raised toward match right whoot thatxe2x80x99s 7000 nonmath majors room xf0x9fx98x82 help us get httpstcotu34c472sd httpstcoqsdqkypsmc\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: btoday comment period potusxe2x80x99s plan expand offshore drilling opened public 60 days march 9 share oppose proposed program directly trump administration comments made email mail httpstcobaaymejxqn\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n",
      "Here's our (cleaned) tweet: bcelebrated icseastlaxe2x80x99s 22 years eastside commitment amp saluted community leaders last nightxe2x80x99s awards dinner httpstco7v7gh8givb\n",
      "Actual party is Democratic and our classifer says republican.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet, party in tweet_data_sample :\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "\n",
    "    print(f\"Here's our (cleaned) tweet: {tweet}\")\n",
    "    print(f\"Actual party is {party} and our classifer says {estimated_party}.\")\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've looked at it some, let's score a bunch and see how we're doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of counts by actual party and estimated party.\n",
    "# The first key is actual, and the second is estimated.\n",
    "parties = ['Republican', 'Democratic']\n",
    "results = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "for p in parties:\n",
    "    for p1 in parties:\n",
    "        results[p][p1] = 0\n",
    "\n",
    "num_to_score = 10000\n",
    "random.shuffle(tweet_data)\n",
    "\n",
    "# Iterate through the tweet data and score the results\n",
    "for idx, tp in enumerate(tweet_data):\n",
    "    tweet, party = tp\n",
    "    \n",
    "    # Get the estimated party using the trained classifier\n",
    "    estimated_party = classifier.classify(conv_features(tweet, feature_words))\n",
    "    \n",
    "    # Update the results dictionary\n",
    "    results[party][estimated_party] += 1\n",
    "\n",
    "    if idx >= num_to_score:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>,\n",
       "            {'Republican': defaultdict(int,\n",
       "                         {'Republican': 0,\n",
       "                          'Democratic': 0,\n",
       "                          'republican': 3580,\n",
       "                          'democratic': 698}),\n",
       "             'Democratic': defaultdict(int,\n",
       "                         {'Republican': 0,\n",
       "                          'Democratic': 0,\n",
       "                          'republican': 4712,\n",
       "                          'democratic': 1011})})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                   china = True           republ : democr =     25.8 : 1.0\n",
      "                   votes = True           democr : republ =     23.8 : 1.0\n",
      "             enforcement = True           republ : democr =     21.5 : 1.0\n",
      "                 destroy = True           republ : democr =     19.2 : 1.0\n",
      "                freedoms = True           republ : democr =     18.2 : 1.0\n",
      "                 climate = True           democr : republ =     17.8 : 1.0\n",
      "                supports = True           republ : democr =     17.1 : 1.0\n",
      "                   crime = True           republ : democr =     16.1 : 1.0\n",
      "                   media = True           republ : democr =     14.9 : 1.0\n",
      "                 beliefs = True           republ : democr =     13.0 : 1.0\n",
      "               countries = True           republ : democr =     13.0 : 1.0\n",
      "                 defense = True           republ : democr =     13.0 : 1.0\n",
      "                    isis = True           republ : democr =     13.0 : 1.0\n",
      "                 liberal = True           republ : democr =     13.0 : 1.0\n",
      "                religion = True           republ : democr =     13.0 : 1.0\n",
      "                   trade = True           republ : democr =     12.7 : 1.0\n",
      "                    flag = True           republ : democr =     12.1 : 1.0\n",
      "               greatness = True           republ : democr =     12.1 : 1.0\n",
      "                 abraham = True           republ : democr =     11.9 : 1.0\n",
      "                  defund = True           republ : democr =     11.9 : 1.0\n",
      "                    drug = True           republ : democr =     10.9 : 1.0\n",
      "              department = True           republ : democr =     10.9 : 1.0\n",
      "               destroyed = True           republ : democr =     10.9 : 1.0\n",
      "                   enemy = True           republ : democr =     10.9 : 1.0\n",
      "               amendment = True           republ : democr =     10.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(25)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reflections\n",
    "\n",
    "This study demonstrated the classification outcomes obtained by employing a Naive Bayes model on the congressional tweets dataset, quantifying both the accurately and inaccurately classified tweets. The model exhibited a higher predictive accuracy for Republicans than Democrats. For the Republican party, the model correctly identified tweets as `Republican` 3,580 times and incorrectly identified tweets as `Democratic` 698 times. For the Democratic party, the model incorrectly identified tweets as `Republican` 4,712 times and correctly identified tweets as `Democratic` 1,011 times."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "c68636a1e49bf3485adde1c0d609ef5e395c0403b8d075633af773dedef405cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
